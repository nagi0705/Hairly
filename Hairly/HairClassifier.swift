import CoreML
import Vision
import UIKit

class HairClassifier {
    static let shared = HairClassifier()
    
    private var model: Hairly_ML_1?
    
    init() {
        do {
            let config = MLModelConfiguration()
            model = try Hairly_ML_1(configuration: config)
            print("âœ… CoreMLãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: \(String(describing: model))")
        } catch {
            print("âŒ CoreMLãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: \(error)")
        }
    }
    
    // ðŸ“Œ ç”»åƒã‚’åˆ†é¡žã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆç¢ºçŽ‡åˆ†å¸ƒã®ãƒ­ã‚°å‡ºåŠ›ã‚’è¿½åŠ ï¼‰
    func classify(image: UIImage, completion: @escaping (String?, HairStyle?) -> Void) {
        guard let model = model else {
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            completion(nil, nil)
            return
        }
        
        guard let pixelBuffer = image.toCVPixelBuffer() else {
            print("âŒ UIImage ã‹ã‚‰ PixelBuffer ã¸ã®å¤‰æ›ã«å¤±æ•—")
            completion(nil, nil)
            return
        }
        
        do {
            let prediction = try model.prediction(image: pixelBuffer)
            let result = prediction.target // ðŸ”¥ èªè­˜ã•ã‚ŒãŸé«ªåž‹ã®ãƒ©ãƒ™ãƒ«
            let probabilities = prediction.targetProbability // ðŸ”¥ é«ªåž‹ã”ã¨ã®ç¢ºçŽ‡åˆ†å¸ƒ
            
            // ðŸ”¥ ç¢ºçŽ‡åˆ†å¸ƒã‚’ãƒ­ã‚°ã«å‡ºåŠ›
            print("âœ… èªè­˜çµæžœ: \(result)")
            print("ðŸ“Š é«ªåž‹ã®ç¢ºçŽ‡åˆ†å¸ƒ: \(probabilities)") // â† ã“ã“ã§å„é«ªåž‹ã®ç¢ºçŽ‡ã‚’ãƒã‚§ãƒƒã‚¯

            // é«ªåž‹ã®èª¬æ˜Žãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            let hairStyleInfo = HairStyleManager.shared.getHairStyleInfo(for: result)
            
            completion(result, hairStyleInfo)
        } catch {
            print("âŒ ç”»åƒè§£æžã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)")
            completion(nil, nil)
        }
    }
}

// ðŸ“Œ UIImage â†’ CVPixelBuffer å¤‰æ›ç”¨ã®æ‹¡å¼µ
extension UIImage {
    func toCVPixelBuffer() -> CVPixelBuffer? {
        let width = 299
        let height = 299
        let attributes: [CFString: Any] = [
            kCVPixelBufferCGImageCompatibilityKey: true,
            kCVPixelBufferCGBitmapContextCompatibilityKey: true
        ]
        var pixelBuffer: CVPixelBuffer?
        let status = CVPixelBufferCreate(kCFAllocatorDefault, width, height,
                                         kCVPixelFormatType_32BGRA,
                                         attributes as CFDictionary,
                                         &pixelBuffer)
        guard status == kCVReturnSuccess, let buffer = pixelBuffer else {
            return nil
        }

        CVPixelBufferLockBaseAddress(buffer, .readOnly)
        let context = CGContext(data: CVPixelBufferGetBaseAddress(buffer),
                                width: width, height: height,
                                bitsPerComponent: 8, bytesPerRow: CVPixelBufferGetBytesPerRow(buffer),
                                space: CGColorSpaceCreateDeviceRGB(),
                                bitmapInfo: CGImageAlphaInfo.noneSkipFirst.rawValue)
        guard let cgImage = self.cgImage else {
            CVPixelBufferUnlockBaseAddress(buffer, .readOnly)
            return nil
        }
        context?.draw(cgImage, in: CGRect(x: 0, y: 0, width: width, height: height))
        CVPixelBufferUnlockBaseAddress(buffer, .readOnly)

        return buffer
    }
}
